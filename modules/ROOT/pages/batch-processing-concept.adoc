= Batch Processing
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]
:keywords: connectors, anypoint, studio, batch, batch processing
:page-aliases: batch-job-concept.adoc, batch-execution-order-faq.adoc

[NOTE]
Batch processing is exclusive to Mule Enterprise runtimes.

Mule allows you to process messages in batches.

Within an application, you can initiate a Batch Job scope, which splits messages into individual records, performs actions upon each record, and then reports on the results and potentially pushes the processed output to other systems or queues.

//_TODO: Check this
// *Are there any message processors that you cannot use in batch processing?*
// The only element you cannot use in batch processing is a *request-response inbound connector.* Otherwise, you are free to leverage any and all Mule message processors to build your batch processing flow.

For example, you can use batch processing when:

* Synchronizing data sets between business applications, such as syncing contacts between NetSuite and Salesforce.
* Extracting, transforming and loading (ETL) information into a target system, such as uploading data from a flat file (CSV) to Hadoop.
* Handling large quantities of incoming data from an API into a legacy system.

If you are already familiar with batch processing in Mule 3.x, you can get an overview of the differences with batch in Mule 4.x in the xref:migration-core-batch.adoc[Migrating the Batch Module] article.

== Overview

Within a Mule application, batch processing provides a construct for
asynchronously processing larger-than-memory data sets that are split
into individual records. Batch jobs allow for the description of a reliable
process that automatically splits up source data and stores it into persistent
queues, which makes it possible to process large data sets while providing
reliability. In the event that the application is redeployed or Mule crashes,
the job execution is able to resume at the point it stopped.

image::batch-main3.png[]

The job is then expressed in terms of processing individual records, providing
semantics for record level variables, aggregation, and error handling.

== Basic Architecture

The heart of Mule's batch processing lies within the batch job. A batch job is a scope that splits large messages into records that Mule processes asynchronously. In the same way flows process messages, batch jobs process records.

image::batch-processing-concept-d1bdd.png[]

The Batch XML structure was modified on Mule 4.0. The example below shows abbreviated details to highlight batch elements.

[source,xml,linenums]
----
<flow name="flowOne">
  <batch:job jobName="batchJob">
    <batch:process-records>

      <batch:step name="batchStep1">
        <event processor/>
        <event processor/>
      </batch:step>

      <batch:step name="batchStep2">
        <event processor/>
        <event processor/>
      </batch:step>
    </batch:process-records>
  </batch:job>
</flow>
----

A batch job contains one or more batch steps that act upon records as they move through the batch job.

Each batch step in a batch job contains processors that act upon a record to transform, route, enrich, or otherwise process data contained within it. By leveraging the functionality of existing Mule processors, the batch step offers a lot of flexibility regarding how a batch job processes records. See xref:batch-filters-and-batch-aggregator.adoc[Refining Batch Steps Processing] for more information.

A batch job executes when the flow reaches the process-records section of the batch job. When triggered, Mule creates a new batch job instance.
When the job instance becomes executable, the batch engine submits a task for each record block to the
I/O pool to process each record. Parallelism occurs automatically, at the record
block level. The Mule runtime engine uses its autotuning capabilities to determine how many threads to use and the level of parallelism to apply (see xref:execution-engine.adoc[Execution Engine]).

When the batch job starts executing, Mule splits the incoming message into records, stores them in a persistent queue, and queries and schedules those records in blocks of records to process. By default, the runtime stores 100 records in each batch step. You can customize this size according to the performance you require. See xref:batch-filters-and-batch-aggregator.adoc[Refining Batch Steps Processing] for more information.

After all the records have passed through all batch steps, the runtime ends the batch job instance and reports the batch job result indicating which records succeeded and which failed during processing.

=== Mule Message Splitting Process

The batch job performs an implicit split operation on the Mule message that recognizes any Java Iterables, Iterators, and Arrays, as well as JSON and XML payloads. The batch job cannot split any other data format. If you are working with a data format that is not compatible with the splitting process, transform the payload to a supported format before it enters the batch job.

=== Error Handling

Batch jobs can handle any record-level failure that might occur in processing to prevent the failure of a complete batch job. Further, you can set or remove variables on individual records so that during batch processing, Mule can route or otherwise act upon records in a batch job according to a variable (assigned above). See xref:batch-error-handling-faq.adoc[Handling Errors During Batch Job] for more information.


=== Batch Job vs. Batch Job Instance

Though defined in context the above, it’s worth elaborating upon the terms _batch job_ and _batch job instance_ as they relate to each other.

* A batch job is the scope element in an application in which Mule processes a message payload as a batch of records. The term batch job is inclusive of all three phases of processing: Load and Dispatch, Process, and On Complete.
* A batch job instance is an occurrence in a Mule application whenever a Mule flow executes a batch job. Mule creates the batch job instance in the Load and Dispatch phase. Every batch job instance is identified internally using a unique String known as batch _job instance id_.

This identifier is useful if you want, for example, to pass the local job instance ID to an external system for referencing and managing data, improve the job’s custom logging, or even send an email or SMS notifications for meaningful events around that specific batch job instance. See xref:batch-job-instance-id.adoc[Batch Job Instance ID] to learn more about this identifier and how to customize it.


== Batch Job Processing Phases

Each batch job contains three different phases:

. Load and Dispatch.
. Process.
. On Complete.


=== Load and Dispatch

This first phase is implicit. When an upstream event in the flow triggers the Batch Job scope, Mule splits the input into records, loads the records into a persistent queue, and starts execution of the instance. This process takes place implicitly, so you do not configure anything to make it occur. However, it is useful to understand the tasks Mule completes during this phase.

. Mule splits input to the scope using DataWeave. The input is a serialized message payload that Mule splits into a collection of records.
+
Note that each record is mutable and has a payload and the same set of attributes or variables that it inherits from the input.
+
This step creates a unique batch job instance. Mule exposes each batch job instance through the `batchJobInstanceId` variable. This variable becomes accessible within every phase batch processing phase for that instance so that you can track operations on records within each instance. The auto-generated identifier is a UUID, but you can change it to a more readable name. For details, see xref:batch-job-instance-id.adoc[].
+
. Mule creates and associated a persistent queue with the new batch job instance.
+
In Anypoint Runtime Manager, the queue name is prefixed with `BSQ`, for example:
+
image:mruntime-batch-bsq.png[Batch step queue transaction log]
+
. For each item generated by the splitter, Mule creates a record and stores it in the queue. This activity is "all or nothing," which means that Mule either successfully generates and queues a record for every item, or the entire event fails during this phase.
. Mule presents the batch job instance and queue of records to its first Batch Step scope for processing.

Each operation within this phase blocks other execution within the flow until it completes. The logs identify them as `BLOCKING` operations.

After this phase completes, the flow continues to execute without waiting for batch processing in the next phase to finish processing the records.

[[phase_process]]
=== Process Phase

The Process phase begins after the Load and Dispatch phase finishes loading records to the queue and starts a batch job instance. All processing takes place within one or more Batch Step scopes within a Batch Job scope and optionally, within a Batch Aggregator scope within one or more of the Batch Step scopes. Processing during this phase is asynchronous from the Mule flow and does not block other, downstream processing within the flow.

//QUESTION: IS THIS THE SAME QUEUE AS THE STEPPING QUEUE DISCUSSED BELOW?
//QUESTION: IS THERE A SEPARATE STEPPING QUEUE FOR EACH BATCH JOB INSTANCE? OR IS IT SHARED ACROSS INSTANCES?
When the Process phase of the batch job instance begins, Mule pulls records from the queue to build record blocks of the configured batch block size. Then Mule sends the record blocks to the Batch Step scope and processes the blocks within the scope asynchronously.

Within the Batch Step scope, processing at the block level takes place parallel, but records within each block process sequentially by default. After processing all the records in a block, the Batch Step scope sends the records to the stepping queue, where the records await processing by the next Batch Step scope within the Batch Job scope, if another is present. This process continues until every record passes through every Batch Step scope. At the end of this phase, all records are consumed. They are not available for further processing by downstream processors in the Mule flow.

Note that it is possible to configure a Batch Step scope to filter the records to process or not within the scope. For details, see xref:batch-filters-and-batch-aggregator.adoc[] for more information.

As a record is processed, it keeps track of each batch step it completes.

image::batch-diagram.jpg[batch+diagram]

[[batch_aggregator_processing]]
By default, a batch job instance does not wait for all its queued records to finish processing in one batch step before pushing them to the next step. Configuring a Batch Aggregator scope (aggregator) changes this behavior:

* Behavior when the Batch Aggregator scope sets a fixed size:
+
In this scenario, the aggregator pulls records from the stepping queue into arrays a fixed size. After processing records in an array, the aggregator sends the records back to the stepping queue for further downstream processing. A processor within the aggregator must be able to receive the array of records as input.
+
image:mruntime-batch-job-process-aggregator-fixed.png[Batch job process with Aggregator with fixed size]
+
<1> The Batch Job scope builds blocks of records limited by the block size configuration (100 per block, by default). This scope sends blocks of records from each batch job instance for processing within a batch step, the first batch step the scope contains if there is more than one step. If fewer records are available than the configured size, the Batch Job scope sends all records from a given batch job instance to the batch step instead of waiting for more to arrive.
/////////
//TODO: THIS MAY NOT BE 100% CLEAR.
// (1) CAN THE RECORDS IN THE BLOCK BE FROM A DIFFERENT INSTANCE? (I think not.)
// (2) WILL THE BATCH STEP EVER WAIT? FOR EXAMPLE, if the block size is 3 but there are 10 records, would _only the last block contain 1 record? Or is it possible for other blocks to contain fewer records than the set size. Everything depends on what's available in the stepping queue for a given instance when the step goes to pick up the records? (Sounds like the latter is true, but need to check.)
/////////
<2> Each Batch Step scope within a Batch Job scope receives one or more record blocks and starts processing them in parallel.
<3> After processing a record, the Batch Step scope sends the record to the Batch Aggregator scope for further processing.
<4> The Batch Aggregator scope places records one or more arrays according to its `size` configuration.
<5> After processing records in a given array, the Batch Aggregator scope sends all the records back to the stepping queue.

* Behavior with Batch Aggregator scope is configured to stream records:
+
In this scenario, the Batch Job scope sends the processed records to its Batch Aggregator scope. The Batch Aggregator scope loads and processes all records for an instance from the stepping queue and continues them until all records from the current batch step are processed and aggregated.
+
image:mruntime-batch-job-process-aggregator-streaming.png[Batch job process with Aggregator configured for Streaming]
+
<1> The batch job builds record blocks of the configured block size and sends them to their corresponding batch step for processing.
<2> Each batch step receives one or more record blocks and starts processing them in parallel.
<3> After the batch step processes a record, the batch step sends the record to the aggregator for further processing.
<4> The aggregator continues processing records until there are no more records in the stepping queue that are waiting to be processed by the current batch step.
<5> The aggregator sends all the aggregated records to the stepping queue.

Mule persists a list of all records that succeed or fail to process through each batch step. If an event processor in a batch step fails to process a record, Mule continues processing the batch, skipping over the failed record in each subsequent batch step.

At the end of this phase, the batch job instance completes and, therefore, ceases to exist.

=== On Complete

During this phase, you can configure the runtime to create a report or summary of the records it processed in a given batch job instance. This phase provides system administrators and developers insight into which records failed or succeeded. This phase does not process or provide access to individual records, nor does it pass processed records to downstream processors in the flow.

Because Mule processes a batch job as an asynchronous, one-way flow, the results of batch processing do not return to the flow, nor do the results return as a response to a caller. Any event source that feeds data into a batch job instance must be one-way, not request-response.


As a best practice, configure a mechanism for reporting on failed or successful records to facilitate further action where required. During the On Complete phase, you can perform either of these tasks:

* Reference the result object for the batch job instance from elsewhere in the Mule application to capture and use batch metadata, such as the number of records that failed to process in a particular batch job instance.
+
TODO: HOW DO WE DO THIS?
+
* Log the result object for each batch job instance.

[source,xml,linenums]
----
<batch:job name="Batch3">
  <batch:process-records>
    <batch:step name="Step1">
      <batch:record-variable-transformer/>
      <ee:transform/>
    </batch:step>
    <batch:step name="Step2">
      <logger/>
      <http:request/>
    </batch:step>
  </batch:process-records>
  <batch:on-complete>
    <logger level="INFO" doc:name="Logger"
            message='#[payload as Object]'/>
  </batch:on-complete>
</batch:job>
----

From the logger set to `payload as Object`, a report looks something like this:

----
INFO  2022-07-06 11:39:02,921 [[MuleRuntime].uber.06:
[w-batch-take6].batch-management-work-manager @56978b97]
[processor: w-batch-take6Flow/processors/3/route/1/processors/0;
 event: e835b2c0-fd5a-11ec-84a5-147ddaaf4f97]
org.mule.runtime.core.internal.processor.LoggerMessageProcessor:
{onCompletePhaseException=null, loadingPhaseException=null, totalRecords=1000, elapsedTimeInMillis=117, failedOnCompletePhase=false, failedRecords=0, loadedRecords=1000, failedOnInputPhase=false, successfulRecords=1000, inputPhaseException=null, processedRecords=10, failedOnLoadingPhase=false, batchJobInstanceId=e84b5da0-fd5a-11ec-84a5-147ddaaf4f97}
----

The fields in the report object (a `BatchJobResult`) are accessible as keys when using DataWeave selectors, such as `payload.failedRecords` to return the number of failed records in the instance.

If you leave the On Complete phase empty and do not reference the batch job result object from elsewhere in your application, the batch job simply completes, whether failed or successful. However, after Mule completes execution of an entire batch job instance, the logs provide some processing information, for example:

----
Finished execution for instance 'e84b5da0-fd5a-11ec-84a5-147ddaaf4f97'
of job 'w-batch-take6Batch_Job'.
Total Records processed: 1000. Successful records: 1000. Failed Records: 0
---

[[variable_propagation]]
=== Variable Propagation

Every processed record of the Batch Job Instance starts with the same variables and values present before the execution of the block. Every record has its own set of variables, so new variables or modifications of already-existing variables during the processing of a given record will not be visible while processing another record. For each record, those variables (and modifications) are propagated through the different Batch Steps. For example, if record R1 sets a variable `varName: "hello"`, record R2 sets `varName: "world"`, and record R3 does not set this variable, then in the next step, R1 will see the value `"hello"`, R2 the value `"world"` and R3 will not see any value for that variable.

In the On Complete phase, none of these variables (not even the original ones) are visible. Only the final result is available in this phase. Moreover, since the Batch Job Instance executes asynchronously from the rest of the flow, no variable set in either a Batch Step or the On Complete phase will be visible outside the Batch Scope.


=== Scheduling Strategy

A Mule application can contain several batch job definitions. Each definition
has its own scheduling strategy. A *Scheduling Strategy* enables you to control
how instances of a given batch job are executed:

* `ORDERED_SQUENTIAL` (the default): If several job instances are in an executable
state at the same time, the instances execute one at a time based on their
creation timestamp.
* `ROUND_ROBIN`: This setting attempts to execute all available instances of a
batch job using a round-robin algorithm to assign the available resources.
+
The `ROUND_ROBIN` option is useful when you can guarantee that no job execution can have a
side effect on another job execution. Therefore, this option is not a good
choice for data synchronization jobs, which can update the same record in two
concurrent jobs. Because the order of the job execution is not guaranteed,
your result might be a prior version of the data. However, you can safely
use this strategy to parallelize the job's execution if your batch job
retrieves only new records from a database or lifts individual files
from an SFTP server, and you are certain that all records are completely
independent.

Note that none of these strategies guarantee that records will be executed in order.
The strategies do not control the execution order of records in the batch job,
nor do they depend on the number of records each instance contains.


== See Also

* xref:batch-filters-and-batch-aggregator.adoc[Refining Batch Steps Processing]
* xref:migration-core-batch.adoc[Migrating the Batch Element]
* xref:transaction-management.adoc#tx_scopes_routers[How Transactions Affect Scopes and Routers]
